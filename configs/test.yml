{ 
  #"use_shared_fs": false,
  "tensorboard_dir": "logs/test/tensorboard",
  "hostfile": "logs/test/hostfile",
  "save": "logs/test/checkpoints",
  "load": "logs/test/checkpoints",
"pipe_parallel_size": 0, 
"model_parallel_size": 2, 
"context_parallel_size": 2, 
"sequence_parallel": true, 
"num_layers": 12, 
"hidden_size": 256, 
"num_attention_heads": 8, 
"seq_length": 1024, 
"max_position_embeddings": 1024, 
"pos_emb": "rotary", 
"rotary_pct": 0.25, 
"no_weight_tying": true, 
"gpt_j_residual": false, 
"output_layer_parallelism": "column", 
"attention_config": [[["ring"], 12]], 
# "scaled_upper_triang_masked_softmax_fusion": true, 
# "bias_gelu_fusion": true, 
"init_method": "small_init", 
"output_layer_init_method": "wang_init", 
"use_qk_layernorm": False, 
"optimizer": { "type": "Adam", "params": { "lr": 0.0003, "betas": [0.9, 0.95], "eps": 1.0e-8 } }, 
"min_lr": 0.00003, 
"zero_optimization": { "stage": 1, "allgather_partitions": true, "allgather_bucket_size": 500000000, "overlap_comm": true, "reduce_scatter": true, "reduce_bucket_size": 500000000, "contiguous_gradients": true, "cpu_offload": false, }, 
"train_micro_batch_size_per_gpu": 32, 
"data_impl": "mmap", 
"num_workers": 1, 
"checkpoint_activations": true, 
"checkpoint_num_layers": 1, 
"partition_activations": false, 
"synchronize_each_layer": true, 
"gradient_clipping": 1.0, 
"weight_decay": 0.1, 
"hidden_dropout": 0, 
"attention_dropout": 0, 
# "fp16": { # "fp16": true, 
# "enabled": true, # "loss_scale": 0, # "loss_scale_window": 1000, # "initial_scale_power": 12, # "hysteresis": 2, # "min_loss_scale": 1 # }, "precision": "bfloat16", 
"fp32_allreduce": true, 
"precision": "bfloat16",
"bf16": { "enabled": true }, 
"train_iters": 1000, 
"lr_decay_iters": 1000, 
"distributed_backend": "nccl", 
"lr_decay_style": "cosine", 
"warmup": 0.01, 
"checkpoint_factor": 10000, 
"extra_save_iters": [100], 
"eval_interval": 100, 
"eval_iters": 50, 
"log_interval": 10, 
"steps_per_print": 10, 
"wall_clock_breakdown": true, 
# "save": "/checkpoint/hielab/brandon/ckpt", # "load": "/checkpoint/hielab/brandon/ckpt", #"load": "/mnt/hdd-0/tiny-pythia/ckpts/pythia-14m", 
"log_grad_norm": true, 
# "data_path": "/mnt/ssd-2/pile_deduped/pile_20B_tokenizer_text_document", # "train-data-paths": ["/mnt/ssd-2/pile_deduped/pile_20B_tokenizer_text_document"], # "valid-data-paths": ["/mnt/ssd-2/pile_deduped/pile_20B_tokenizer_text_document"], # "test-data-paths": ["/mnt/ssd-2/pile_deduped/pile_20B_tokenizer_text_document"], 
}
