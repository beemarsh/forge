#!/bin/bash -l
#SBATCH -J gpt
#SBATCH -t 0:10:00
#SBATCH -N 4
#SBATCH -C nvme
#SBATCH --exclusive
#SBATCH --ntasks-per-node=8
#SBATCH -o neox.o%j
#SBATCH -e neox.e%j
#SBATCH -q DEBUG
#SBATCH -A gen243

MODEL=forge-s
rocm_version=5.3.0

source neox-env.sh 

export LD_LIBRARY_PATH=/lustre/orion/gen243/proj-shared/bbdir/forge/aws-ofi-rccl/lib:$LD_LIBRARY_PATH

export HCC_AMDGPU_TARGET=gfx90a
export PYTORCH_ROCM_ARCH=gfx90a
export LD_LIBRARY_PATH=/opt/rocm-$rocm_version/hip/lib:$LD_LIBRARY_PATH


export HOSTNAMES=`scontrol show hostnames "$SLURM_JOB_NODELIST"`

./generate_hostfile.sh

cur_dir=$(pwd)
host_dir="${cur_dir}/hostfiles"

export DLTS_HOSTFILE="${host_dir}/hosts_${SLURM_JOBID}"

export NUMEXPR_MAX_THREADS=56


export FI_MR_CACHE_MONITOR=kdreg2     # Required to avoid a deadlock.
export FI_CXI_DEFAULT_CQ_SIZE=131072  # Ask the network stack to allocate additional space to process message completions.
export FI_CXI_DEFAULT_TX_SIZE=2048    # Ask the network stack to allocate additional space to hold pending outgoing messages.
export FI_CXI_RX_MATCH_MODE=hybrid    # Allow the network stack to transition to software mode if necessary.

export NCCL_NET_GDR_LEVEL=3           # Typically improves performance, but remove this setting if you encounter a hang/crash.
export NCCL_CROSS_NIC=1               # On large systems, this NCCL setting has been found to improve performance
export NCCL_SOCKET_IFNAME=hsn0        # NCCL/RCCL will use the high speed network to coordinate startup.

NCCL_DEBUG=info

echo "PATH=$PATH" > .deepspeed_env
echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH" >> .deepspeed_env
echo "CPATH=$CPATH" >> .deepspeed_env
echo "CUDAPATH=${ROCM_PATH}" >> .deepspeed_env
echo "TORCH_EXTENSIONS_DIR=$(pwd)/deepspeed" >> .deepspeed_env
echo "NCCL_DEBUG=INFO" >> .deepspeed_env
echo "FI_CXI_ATS=0" >> .deepspeed_env
echo "NCCL_SOCKET_IFNAME=hsn" >> .deepspeed_env

python -u ./deepy.py train.py -d configs ${MODEL}.yml frontier.yml
